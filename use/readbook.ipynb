{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 导入",
   "id": "9a58201909bf6b23"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:12:14.139977Z",
     "start_time": "2024-04-11T14:12:11.147307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import networkx as nx\n",
    "import jieba.posseg as pseg  # 引入词性标注接口\n",
    "# 导入random包\n",
    "import random\n",
    "import codecs\n",
    "from pyecharts.charts import WordCloud\n",
    "from pyecharts.charts import Line\n",
    "import wordcloud\n",
    "import imageio\n",
    "mainTop = 15"
   ],
   "id": "5127dcf593fd6b0d",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e87bbee0b57ba7a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:12:15.331818Z",
     "start_time": "2024-04-11T14:12:15.318310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_txt():\n",
    "    file = open('D:\\s\\三国演义.txt',encoding='utf-8')\n",
    "    txt = file.read()\n",
    "    file.close()\n",
    "    return txt"
   ],
   "id": "37359ebc840fe1b",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 停顿词处理",
   "id": "d0e45ecc54a95191"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:12:16.647550Z",
     "start_time": "2024-04-11T14:12:16.627953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "txt = read_txt()\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "excludes = {'将军', '却说', '令人', '赶来', '徐州', '不见', '下马', '喊声', '因此', '未知', '大败', '百姓', '大事',\n",
    "            '一军', '之后', '接应', '起兵',\n",
    "            '成都', '原来', '江东', '正是', '忽然', '原来', '大叫', '上马', '天子', '一面', '太守', '不如', '忽报',\n",
    "            '后人', '背后', '先主', '此人',\n",
    "            '城中', '然后', '大军', '何不', '先生', '何故', '夫人', '不如', '先锋', '二人', '不可', '如何', '荆州',\n",
    "            '不能', '如此', '主公', '军士',\n",
    "            '商议', '引兵', '次日', '大喜', '魏兵', '军马', '于是', '东吴', '今日', '左右', '天下', '不敢', '陛下',\n",
    "            '人马', '不知', '都督', '汉中',\n",
    "            '一人', '众将', '后主', '只见', '蜀兵', '马军', '黄巾', '立功', '白发', '大吉', '红旗', '士卒', '钱粮',\n",
    "            '于汉', '郎舅', '龙凤', '古之', '白虎',\n",
    "            '古人云', '尔乃', '马飞报', '轩昂', '史官', '侍臣', '列阵', '玉玺', '车驾', '老夫', '伏兵', '都尉', '侍中',\n",
    "            '西凉', '安民', '张曰', '文武', '白旗',\n",
    "            '祖宗', '寻思'}  # 排除的词汇\n"
   ],
   "id": "4559eeb02e867d01",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# # 通过键值对的形式存储词语及其出现的次数",
   "id": "b4e0f40dc9b0775d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:02:20.468249Z",
     "start_time": "2024-04-11T14:02:20.444868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "counts = {} # 通过键值对的形式存储词语及其出现的次数\n",
    "def getWordTimes():\n",
    "    # 分词，返回词性\n",
    "    poss = pseg.cut(txt)\n",
    "    for w in poss:\n",
    "        if w.flag != 'nr' or len(w.word) < 2 or w.word in excludes:\n",
    "            continue  # 当分词长度小于2或该词词性不为nr（人名）时认为该词不为人名\n",
    "        elif w.word == '孔明' or w.word == '孔明曰' or w.word == '卧龙先生':\n",
    "            real_word = '诸葛亮'\n",
    "        elif w.word == '云长' or w.word == '关公曰' or w.word == '关公':\n",
    "            real_word = '关羽'\n",
    "        elif w.word == '玄德' or w.word == '玄德曰' or w.word == '玄德甚' or w.word == '玄德遂' or w.word == '玄德兵' or w.word == '玄德领' \\\n",
    "                or w.word == '玄德同' or w.word == '刘豫州' or w.word == '刘玄德':\n",
    "            real_word = '刘备'\n",
    "        elif w.word == '孟德' or w.word == '丞相' or w.word == '曹贼' or w.word == '阿瞒' or w.word == '曹丞相' or w.word == '曹将军':\n",
    "            real_word = '曹操'\n",
    "        elif w.word == '高祖':\n",
    "            real_word = '刘邦'\n",
    "        elif w.word == '光武':\n",
    "            real_word = '刘秀'\n",
    "        elif w.word == '桓帝':\n",
    "            real_word = '刘志'\n",
    "        elif w.word == '灵帝':\n",
    "            real_word = '刘宏'\n",
    "        elif w.word == '公瑾':\n",
    "            real_word = '周瑜'\n",
    "        elif w.word == '伯符':\n",
    "            real_word = '孙策'\n",
    "        elif w.word == '吕奉先' or w.word == '布乃' or w.word == '布大怒' or w.word == '吕布之':\n",
    "            real_word = '吕布'\n",
    "        elif w.word == '赵子龙' or w.word == '子龙':\n",
    "            real_word = '赵云'\n",
    "        elif w.word == '卓大喜' or w.word == '卓大怒':\n",
    "            real_word = '董卓'  # 把相同意思的名字归为一个人\n",
    "        else:\n",
    "            real_word = w.word\n",
    "        counts[real_word] = counts.get(real_word, 0) + 1\n"
   ],
   "id": "3c993e088b4baae9",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 降序排列",
   "id": "18ce9c17f5a623a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:03:08.561725Z",
     "start_time": "2024-04-11T14:02:20.551877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "getWordTimes()\n",
    "items = list(counts.items())\n",
    "# 进行降序排列 根据词语出现的次数进行从大到小排序\n",
    "items.sort(key=lambda x: x[1], reverse=True)"
   ],
   "id": "93ad33dca82882cc",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 结果",
   "id": "65e3d771dd338b85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:03:08.577370Z",
     "start_time": "2024-04-11T14:03:08.562717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def wordFreq(filepath, topn):\n",
    "    with codecs.open(filepath, \"w\", \"utf-8\") as f:\n",
    "        for i in range(topn):\n",
    "            word, count = items[i]\n",
    "            f.write(\"{}:{}\\n\".format(word, count))\n",
    "wordFreq(\"三国演义词频_人名.txt\", 300)\n",
    "fr = open('三国演义词频_人名.txt', 'r', encoding='utf-8')\n",
    "dic = {}\n",
    "keys = []  # 用来存储读取的顺序\n",
    "for line in fr:\n",
    "    # 去空白,并用split()方法返回列表\n",
    "    v = line.strip().split(':')\n",
    "    # print(\"v\",v)   # v ['诸葛亮', '1373']\n",
    "    # 拼接字典 {'诸葛亮', '1373'}\n",
    "    dic[v[0]] = v[1]\n",
    "    keys.append(v[0])\n",
    "fr.close()\n",
    "# 输出前几个的键值对\n",
    "print(\"人物出现次数:\", mainTop)\n",
    "print(list(dic.items())[:mainTop])"
   ],
   "id": "b0419ab17a063276",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 绘图操作",
   "id": "86b820e2bd12554a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:03:08.592897Z",
     "start_time": "2024-04-11T14:03:08.579373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "list_name = list(dic.keys())  # 人名\n",
    "list_name_times = list(dic.values())  # 提取字典里的数据作为绘图数据"
   ],
   "id": "cf9168bc89c4a4d5",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:03:08.608518Z",
     "start_time": "2024-04-11T14:03:08.594901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyecharts.charts import Bar\n",
    "from pyecharts import options as opts\n",
    "def creat_people_view():\n",
    "    bar = Bar()\n",
    "    bar.add_xaxis(list_name[0:mainTop])\n",
    "    bar.add_yaxis(\"人物出场次数\", list_name_times)\n",
    "    bar.set_global_opts(title_opts=opts.TitleOpts(title=\"人物出场次数可视化图\", subtitle=\"三国人物TOP\" + str(mainTop)),\n",
    "                        toolbox_opts=opts.ToolboxOpts(is_show=True),\n",
    "                        xaxis_opts=opts.AxisOpts(axislabel_opts={\"rotate\": 45}))\n",
    "    bar.set_series_opts(label_opts=opts.LabelOpts(position=\"top\"))\n",
    "    bar.render_notebook()  # 在 notebook 中展示\n",
    "    bar.render(\"三国演义人物出场次数可视化图.html\")"
   ],
   "id": "1dbcadd82fe9d7e4",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 生成词云",
   "id": "bc87ba7c7edc669d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:03:08.639703Z",
     "start_time": "2024-04-11T14:03:08.610516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bg_pic = imageio.imread('D:\\\\s\\\\alice-mask.png')\n",
    "# 定义文件路径  \n",
    "file_path = r\"C:\\Users\\33079\\PycharmProjects\\pys\\三国演义词频_人名.txt\"  \n",
    "  \n",
    "# 创建一个空字典来存储词频  \n",
    "word_freq_dict = {}  \n",
    "  \n",
    "# 尝试打开文件并读取内容  \n",
    "try:  \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:  \n",
    "        # 遍历文件的每一行  \n",
    "        for line in file:  \n",
    "            # 去除行尾的换行符并以冒号分隔键和值  \n",
    "            key, value = line.strip().split(':')  \n",
    "            # 去除值两侧的空格并将其转换为整数  \n",
    "            value = int(value.strip())  \n",
    "            # 将键和值添加到字典中  \n",
    "            word_freq_dict[key] = value  \n",
    "except FileNotFoundError:  \n",
    "    print(f\"文件 {file_path} 未找到。\")  \n",
    "except Exception as e:  \n",
    "    print(f\"读取文件时出错: {e}\")  \n",
    "  \n",
    "\n",
    "def creat_wordcloud():\n",
    "    wc = wordcloud.WordCloud(font_path='D:\\\\s\\\\simhei.ttf',\n",
    "                               background_color='white',\n",
    "                             width=1000, height=800,\n",
    "                             # stopwords=excludes,# 设置停用词\n",
    "                             max_words=500,\n",
    "                             mask=bg_pic  # mask参数设置词云形状\n",
    "                             )\n",
    "    # 从单词和频率创建词云\n",
    "    wc.generate_from_frequencies(word_freq_dict)\n",
    "    # generate(text)  根据文本生成词云\n",
    "    # wc.generate(txt)\n",
    "    # 保存图片\n",
    "    wc.to_file('三国演义词云_人名.png')\n",
    "\n",
    "    #  显示词云图片\n",
    "    plt.imshow(wc)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def creat_wordcloud_pyecharts():\n",
    "    wordsAndTimes = list(dic.items())\n",
    "    (\n",
    "        WordCloud()\n",
    "        .add(series_name=\"人物次数\", data_pair=wordsAndTimes,\n",
    "             word_size_range=[20, 100], textstyle_opts=opts.TextStyleOpts(font_family=\"cursive\"), )\n",
    "        .set_global_opts(title_opts=opts.TitleOpts(title=\"三国演义词云\"))\n",
    "        .render(\"三国演义词云_人名.html\")\n",
    "    )\n"
   ],
   "id": "62e21f1b696b168d",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 生成章回字数",
   "id": "77f41269f7f18912"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:03:08.655861Z",
     "start_time": "2024-04-11T14:03:08.640704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chapter_word():\n",
    "    # 进行章回切片\n",
    "    list2 = txt.split(\"------------\")\n",
    "    chapter_list = [i for i in range((len(list2)))]\n",
    "    word_list = [len(i) for i in list2]\n",
    "\n",
    "    (\n",
    "        Line(init_opts=opts.InitOpts(width=\"1400px\", height=\"700px\"))\n",
    "        .add_xaxis(xaxis_data=chapter_list)\n",
    "        .add_yaxis(\n",
    "            series_name=\"章回字数\",\n",
    "            y_axis=word_list,\n",
    "            markpoint_opts=opts.MarkPointOpts(\n",
    "                data=[\n",
    "                    opts.MarkPointItem(type_=\"max\", name=\"最大值\"),\n",
    "                    opts.MarkPointItem(type_=\"min\", name=\"最小值\"),\n",
    "                ]\n",
    "            ),\n",
    "            markline_opts=opts.MarkLineOpts(\n",
    "                data=[opts.MarkLineItem(type_=\"average\", name=\"平均值\")]\n",
    "            ),\n",
    "        )\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(title=\"三国演义章回字数\", subtitle=\"\"),\n",
    "            tooltip_opts=opts.TooltipOpts(trigger=\"axis\"),\n",
    "            toolbox_opts=opts.ToolboxOpts(is_show=True),\n",
    "            xaxis_opts=opts.AxisOpts(type_=\"category\", boundary_gap=False),\n",
    "        )\n",
    "        .render(\"三国演义章回字数.html\")\n",
    "    )\n"
   ],
   "id": "afe8ba613a12290f",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 颜色处理",
   "id": "7edae2479a48be73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:03:08.671899Z",
     "start_time": "2024-04-11T14:03:08.657863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "colorNum = len(list_name[0:mainTop])\n",
    "def randomcolor():\n",
    "    colorArr = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F']\n",
    "    color = \"\"\n",
    "    for i in range(6):\n",
    "        color += colorArr[random.randint(0, 14)]\n",
    "    return \"#\" + color\n",
    "\n",
    "\n",
    "def color_list():\n",
    "    colorList = []\n",
    "    for i in range(colorNum):\n",
    "        colorList.append(randomcolor())\n",
    "\n",
    "    return colorList"
   ],
   "id": "86891b4c4b30fb",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 生成人物关系图",
   "id": "cdadf3c63fd148d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:03:08.718703Z",
     "start_time": "2024-04-11T14:03:08.673891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def creat_relationship():\n",
    "    # 人物节点颜色\n",
    "    colors = color_list()\n",
    "    Names = list_name[0:mainTop]\n",
    "    relations = {}\n",
    "    # 按段落划分，假设在同一段落中出现的人物具有共现关系\n",
    "    lst_para = (txt).split('\\n')  # lst_para是每一段\n",
    "    for text in lst_para:\n",
    "        for name_0 in Names:\n",
    "            if name_0 in text:\n",
    "                for name_1 in Names:\n",
    "                    if name_1 in text and name_0 != name_1 and (name_1, name_0) not in relations:\n",
    "                        relations[(name_0, name_1)] = relations.get((name_0, name_1), 0) + 1\n",
    "    maxRela = max([v for k, v in relations.items()])\n",
    "    relations = {k: v / maxRela for k, v in relations.items()}\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    # 创建无多重边无向图\n",
    "    G = nx.Graph()\n",
    "    for k, v in relations.items():\n",
    "        G.add_edge(k[0], k[1], weight=v)\n",
    "    # 筛选权重大于0.6的边\n",
    "    elarge = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] > 0.6]\n",
    "    # 筛选权重大于0.3小于0.6的边\n",
    "    emidle = [(u, v) for (u, v, d) in G.edges(data=True) if (d['weight'] > 0.3) & (d['weight'] <= 0.6)]\n",
    "    # 筛选权重小于0.3的边\n",
    "    esmall = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] <= 0.3]\n",
    "    # 设置图形布局\n",
    "    pos = nx.spring_layout(G)  # 用Fruchterman-Reingold算法排列节点（样子类似多中心放射状）\n",
    "    # 设置节点样式\n",
    "    nx.draw_networkx_nodes(G, pos, alpha=0.8, node_size=1300, node_color=colors)\n",
    "    # 设置大于0.6的边的样式\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=elarge, width=2.5, alpha=0.9, edge_color='g')\n",
    "    # 0.3~0.6\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=emidle, width=1.5, alpha=0.6, edge_color='y')\n",
    "    # <0.3\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=esmall, width=1, alpha=0.4, edge_color='b', style='dashed')\n",
    "    nx.draw_networkx_labels(G, pos, font_size=14)\n",
    "\n",
    "    plt.title(\"《三国演义》主要人物社交关系网络图\")\n",
    "    # 关闭坐标轴\n",
    "    plt.axis('off')\n",
    "\n",
    "    # 保存图表\n",
    "    plt.savefig('《三国演义》主要人物社交关系网络图.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n"
   ],
   "id": "4290374868ccbfe0",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:08:36.194619Z",
     "start_time": "2024-04-11T14:08:36.154783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    # 人物出场次数可视化图\n",
    "    creat_people_view()\n",
    "    # 词云图\n",
    "    creat_wordcloud()\n",
    "    creat_wordcloud_pyecharts()\n",
    "    # 人物关系图\n",
    "    creat_relationship()\n",
    "    # 章回字数\n",
    "    chapter_word()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "id": "a40a696c3f9b3b3c",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:08:33.145755Z",
     "start_time": "2024-04-11T14:08:33.106033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "bg_pic = imageio.imread('D:\\\\s\\\\alice-mask.png')\n",
    "\n",
    "file_path = r\"C:\\Users\\33079\\PycharmProjects\\pys\\三国演义词频_人名.txt\"\n",
    "word_freq_dict = {}\n",
    "\n",
    "try:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            key, value = line.strip().split(':')\n",
    "            value = int(value.strip())\n",
    "            word_freq_dict[key] = value\n",
    "except FileNotFoundError:\n",
    "    print(f\"文件 {file_path} 未找到。\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"读取文件时出错: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "def creat_wordcloud():\n",
    "    wc = wordcloud.WordCloud(font_path='D:\\s\\simhei.ttf',\n",
    "                             background_color='white',\n",
    "                             width=1000, height=800,\n",
    "                             max_words=500,\n",
    "                             )\n",
    "    wc.generate_from_frequencies(word_freq_dict)\n",
    "    wc.to_file('三国演义词云_人名.png')\n",
    "    plt.imshow(wc)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "creat_wordcloud()\n"
   ],
   "id": "4836e8c960c9bb35",
   "execution_count": 17,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
