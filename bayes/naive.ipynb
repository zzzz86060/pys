{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 朴素贝叶斯 鸢尾花\n",
   "id": "97fcbcb7d529aea"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x,y = load_iris().data,load_iris().target\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1,test_size=50)\n",
    "len(x_test)\n",
    "\n",
    "\n",
    "#训练模型\n",
    "model = GaussianNB()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "#评估\n",
    "pred = model.predict(x_test)\n",
    "print('预测集数据的预测标签是：',pred)\n",
    "print('测试机数据的真实标签是:',y_test)\n",
    "acc = accuracy_score(y_test,pred)\n",
    "print('预测的准确率是：',acc)\n",
    "sum(pred!=y_test)"
   ],
   "id": "e51866bf1485c641",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 垃圾邮件",
   "id": "fdff3082d250a0a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:57:07.440306Z",
     "start_time": "2024-04-23T02:57:07.425323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os \n",
    "normalFileList = os.listdir('../bayes/normal')\n",
    "spamFileList = os.listdir('../bayes/spam')\n",
    "print('正常邮件列表为：',normalFileList)\n",
    "print('垃圾邮件列表为：',spamFileList)"
   ],
   "id": "ed319db6be7ee7b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正常邮件列表为： ['normal-mail1.txt', 'normal-mail2.txt', 'normal-mail3.txt', 'normal-mail4.txt', 'normal-mail5.txt', 'normal-mail6.txt', 'normal-mail7.txt', 'normal-mail8.txt', 'normal-mail9.txt']\n",
      "垃圾邮件列表为： ['spam-mail1.txt', 'spam-mail2.txt', 'spam-mail3.txt', 'spam-mail4.txt', 'spam-mail5.txt', 'spam-mail6.txt', 'spam-mail7.txt', 'spam-mail8.txt', 'spam-mail9.txt']\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:57:25.319666Z",
     "start_time": "2024-04-23T02:57:25.304535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stopList = []\n",
    "for line in open('../bayes/stopwords.txt','r',encoding='utf-8'):\n",
    "    stopList.append(line[:len(line) - 1])\n",
    "print(stopList)"
   ],
   "id": "344f0c1b2584c3d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['啊', '阿', '哎', '哎呀', '唉', '于是', '还']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:57:27.039149Z",
     "start_time": "2024-04-23T02:57:27.010557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from jieba import cut\n",
    "from re import sub\n",
    "\n",
    "def getWord(file,stopList):\n",
    "    wordslist = []\n",
    "    for line in open(file,encoding='utf-8'):\n",
    "        line = line.strip()\n",
    "        line = sub(r'[.【】0-9、——，。！\\~*]','',line)\n",
    "        line = cut(line)\n",
    "        line = filter(lambda word:len(word) > 1,line)\n",
    "        wordslist.extend(line)\n",
    "        words = []\n",
    "        for i in wordslist:\n",
    "            if i not in stopList and i.strip() != '' and i != None:\n",
    "                words.append(i)\n",
    "                \n",
    "    return words\n",
    "        "
   ],
   "id": "cb70acbc06129f6a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:57:47.680384Z",
     "start_time": "2024-04-23T02:57:46.844383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "allwords = []\n",
    "for normalfile in normalFileList:\n",
    "    words = getWord('../bayes/normal/'+normalfile,stopList)\n",
    "    allwords.append(words)\n",
    "for spamfile in spamFileList:\n",
    "    words = getWord('../bayes/spam/'+spamfile,stopList)\n",
    "    allwords.append(words)\n",
    "print('训练集中所有的有效词语列表：',allwords)"
   ],
   "id": "419d7e7b49c8f8f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\33079\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.803 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集中所有的有效词语列表： [['张老师', '您好', '上次', '推荐', '资料', '来说', '帮助', '很大', '希望', '推荐', '一些', '资料', '非常感谢'], ['小李', '你好', '论文', '需要', '修改', '具体', '修改意见', '附件', '查收'], ['李老师', '您好', '论文', '已经', '修改', '修改', '完成', '内容', '附件', '查收'], ['小李', '你好', '论文', '需要', '修改', '具体', '修改意见', '附件', '查收'], ['小张', '你好', '论文', '需要', '修改', '具体', '修改意见', '附件', '查收'], ['张老师', '您好', '论文', '修改', '具体内容', '附件', '查收'], ['李老师', '你好', '论文', '修改', '中等', '修改', '完成', '沟通'], ['小张', '你好', '论文', '需要', '修改', '具体', '修改意见', '附件', '查收'], ['小张', '你好', '论文', '需要', '修改', '具体', '修改意见', '附件', '查收'], ['期刊', '主要', '栏目', '技术', '应用', '投稿', '邮箱', 'xx', 'com'], ['期刊', '主要', '栏目', '数据', '投稿', '邮箱', 'xx', 'com'], ['某某', '期刊', '主要', '栏目', '数据', '投稿', '邮箱', 'xx', 'com'], ['期刊', '主要', '栏目', '计算', '投稿', '邮箱', 'xx', 'com'], ['期刊', '主要', '栏目', '人工智能', '投稿', '邮箱', 'xx', 'com'], ['期刊', '主要', '栏目', '网络设备', '投稿', '邮箱', 'xx', 'com'], ['期刊', '主要', '栏目', '计算机', '基础', '投稿', '邮箱', 'xx', 'com'], ['期刊', '主要', '栏目', '网络', '制图', '投稿', '邮箱', 'xx', 'com'], ['期刊', '主要', '栏目', '网站', '绘图', '投稿', '邮箱', 'xx', 'com']]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:00:23.875167Z",
     "start_time": "2024-04-23T03:00:23.863155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "frep = Counter(chain(*allwords))\n",
    "topTen = frep.most_common(10)\n",
    "topTen\n",
    "topWords = [i[0] for i in topTen]\n",
    "print('训练集中出现频率最高的10个词语是：',topWords)\n"
   ],
   "id": "263a849d6f6341a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集中出现频率最高的10个词语是： ['修改', '期刊', '主要', '栏目', '投稿', '邮箱', 'xx', 'com', '论文', '附件']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:20:28.209177Z",
     "start_time": "2024-04-23T03:20:28.191181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "vector = []\n",
    "for words in allwords:\n",
    "    temp = list(map(lambda x:words.count(x),topWords))\n",
    "    vector.append(temp)\n",
    "vector = np.array(vector)\n",
    "print('10个高频词语在每封邮件中出现的次数：\\n',vector)"
   ],
   "id": "46e8add417e441c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10个高频词语在每封邮件中出现的次数：\n",
      " [[0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 1 1]\n",
      " [2 0 0 0 0 0 0 0 1 1]\n",
      " [1 0 0 0 0 0 0 0 1 1]\n",
      " [1 0 0 0 0 0 0 0 1 1]\n",
      " [1 0 0 0 0 0 0 0 1 1]\n",
      " [2 0 0 0 0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 0 1 1]\n",
      " [1 0 0 0 0 0 0 0 1 1]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 1 1 1 0 0]]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:25:03.475273Z",
     "start_time": "2024-04-23T03:25:03.461194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "target = np.array([0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1])\n",
    "\n",
    "x,y = vector,target\n",
    "model = MultinomialNB()\n",
    "model.fit(x,y)\n"
   ],
   "id": "3ead09ce018d584e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:29:50.934281Z",
     "start_time": "2024-04-23T03:29:50.916263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = os.listdir('../bayes/test')\n",
    "for testFile in test:\n",
    "    words = getWord('../bayes/test/'+testFile,stopList)\n",
    "    test_x = np.array(tuple(map(lambda word:words.count(word),topWords)))\n",
    "    result = model.predict(test_x.reshape(1,-1))\n",
    "    if result == 1:\n",
    "        print(testFile,'为垃圾邮件')\n",
    "    else:\n",
    "        print(testFile,'为正常邮件')"
   ],
   "id": "bd28e408c64dea2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal-test.txt 为正常邮件\n",
      "spam-test.txt 为垃圾邮件\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
